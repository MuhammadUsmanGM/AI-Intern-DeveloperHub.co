{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 6: House Price Prediction\n",
        "\n",
        "## Objective\n",
        "Predict house prices using property features such as size, bedrooms, location, and other real estate characteristics.\n",
        "\n",
        "## Dataset\n",
        "House Price Prediction Dataset (available on Kaggle)\n",
        "\n",
        "## Problem Statement\n",
        "Real estate pricing is a critical application of machine learning in the finance and property sectors. Accurate price predictions help buyers, sellers, and investors make informed decisions. Using various property features like square footage, number of bedrooms, bathrooms, location, age of the house, and amenities, we can build regression models to predict market prices. This is a continuous value prediction (regression) problem where we estimate the sale price based on property characteristics.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and Inspect the Dataset\n",
        "\n",
        "**Note:** Download house_prices.csv from Kaggle or create a sample dataset.\n",
        "Link: https://www.kaggle.com/datasets/c1714457c52b8a4f366991e48d4e3af4/housing-prices-dataset-with-latitude-longitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample house price dataset if needed\n",
        "# Or load from CSV: df = pd.read_csv('house_prices.csv')\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate sample house price dataset\n",
        "n_samples = 500\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'SquareFeet': np.random.uniform(800, 5000, n_samples),\n",
        "    'Bedrooms': np.random.randint(1, 6, n_samples),\n",
        "    'Bathrooms': np.random.uniform(1, 4, n_samples),\n",
        "    'YearBuilt': np.random.randint(1950, 2023, n_samples),\n",
        "    'Garage': np.random.randint(0, 4, n_samples),\n",
        "    'Pool': np.random.randint(0, 2, n_samples),\n",
        "    'Lot_Size': np.random.uniform(0.5, 2, n_samples),\n",
        "})\n",
        "\n",
        "# Generate prices based on features with some correlation\n",
        "df['Price'] = (\n",
        "    150 * df['SquareFeet'] +\n",
        "    50000 * df['Bedrooms'] +\n",
        "    30000 * df['Bathrooms'] +\n",
        "    2000 * (2023 - df['YearBuilt']) +  # Negative: older houses worth less\n",
        "    20000 * df['Garage'] +\n",
        "    100000 * df['Pool'] +\n",
        "    50000 * df['Lot_Size'] +\n",
        "    np.random.normal(0, 50000, n_samples)  # Add noise\n",
        ")\n",
        "\n",
        "# Ensure prices are positive\n",
        "df['Price'] = np.abs(df['Price'])\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Inspection and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data types and missing values\n",
        "print(\"Data Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nDataset Shape:\")\n",
        "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary statistics\n",
        "print(\"Summary Statistics:\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of target variable (Price)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram\n",
        "axes[0].hist(df['Price'], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title('Distribution of House Prices', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Price ($)', fontsize=11)\n",
        "axes[0].set_ylabel('Frequency', fontsize=11)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Box plot\n",
        "axes[1].boxplot(df['Price'])\n",
        "axes[1].set_title('Box Plot of House Prices', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Price ($)', fontsize=11)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Price Statistics:\")\n",
        "print(f\"  Mean: ${df['Price'].mean():,.2f}\")\n",
        "print(f\"  Median: ${df['Price'].median():,.2f}\")\n",
        "print(f\"  Std Dev: ${df['Price'].std():,.2f}\")\n",
        "print(f\"  Min: ${df['Price'].min():,.2f}\")\n",
        "print(f\"  Max: ${df['Price'].max():,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "plt.figure(figsize=(12, 8))\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, fmt='.2f')\n",
        "plt.title('Correlation Matrix - House Features and Price', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relationship between features and price\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "features = ['SquareFeet', 'Bedrooms', 'Bathrooms', 'YearBuilt', 'Garage', 'Lot_Size']\n",
        "\n",
        "for idx, feature in enumerate(features):\n",
        "    axes[idx].scatter(df[feature], df['Price'], alpha=0.5, s=30, color='steelblue')\n",
        "    axes[idx].set_xlabel(feature, fontsize=11)\n",
        "    axes[idx].set_ylabel('Price ($)', fontsize=11)\n",
        "    axes[idx].set_title(f'{feature} vs Price', fontsize=12, fontweight='bold')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values and handle them\n",
        "print(\"Handling missing values...\")\n",
        "df_clean = df.dropna()  # Drop rows with missing values\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(f\"Clean dataset shape: {df_clean.shape}\")\n",
        "print(f\"Rows removed: {df.shape[0] - df_clean.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_clean.drop('Price', axis=1)\n",
        "y = df_clean['Price']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nFeature columns:\")\n",
        "print(X.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")\n",
        "print(f\"\\nTraining target statistics:\")\n",
        "print(f\"  Mean: ${y_train.mean():,.2f}\")\n",
        "print(f\"  Std Dev: ${y_train.std():,.2f}\")\n",
        "print(f\"\\nTesting target statistics:\")\n",
        "print(f\"  Mean: ${y_test.mean():,.2f}\")\n",
        "print(f\"  Std Dev: ${y_test.std():,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature scaling using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features scaled successfully!\")\n",
        "print(f\"\\nScaled training data shape: {X_train_scaled.shape}\")\n",
        "print(f\"Scaled testing data shape: {X_test_scaled.shape}\")\n",
        "print(f\"\\nScaled data - Mean (should be ~0): {X_train_scaled.mean(axis=0)[:3]}\")\n",
        "print(f\"Scaled data - Std (should be ~1): {X_train_scaled.std(axis=0)[:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Model Training - Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Linear Regression Model\n",
        "print(\"Training Linear Regression Model...\")\n",
        "lin_reg_model = LinearRegression()\n",
        "lin_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lin = lin_reg_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Linear Regression Model trained successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Linear Regression\n",
        "mae_lin = mean_absolute_error(y_test, y_pred_lin)\n",
        "rmse_lin = np.sqrt(mean_squared_error(y_test, y_pred_lin))\n",
        "r2_lin = r2_score(y_test, y_pred_lin)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LINEAR REGRESSION MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_lin:,.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): ${rmse_lin:,.2f}\")\n",
        "print(f\"R\u00b2 Score: {r2_lin:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Model Training - Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Gradient Boosting Model\n",
        "print(\"Training Gradient Boosting Regressor Model...\")\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_gb = gb_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Gradient Boosting Model trained successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Gradient Boosting\n",
        "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"GRADIENT BOOSTING MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_gb:,.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): ${rmse_gb:,.2f}\")\n",
        "print(f\"R\u00b2 Score: {r2_gb:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison dataframe\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Linear Regression', 'Gradient Boosting'],\n",
        "    'MAE': [mae_lin, mae_gb],\n",
        "    'RMSE': [rmse_lin, rmse_gb],\n",
        "    'R\u00b2 Score': [r2_lin, r2_gb]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Determine best model\n",
        "best_model = 'Gradient Boosting' if r2_gb > r2_lin else 'Linear Regression'\n",
        "print(f\"\\nBest Model (based on R\u00b2 Score): {best_model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Visualization - Actual vs Predicted Prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Linear Regression predictions\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "test_indices = np.arange(len(y_test))\n",
        "\n",
        "plt.plot(test_indices, y_test.values, 'o-', label='Actual Prices', \n",
        "         markersize=6, linewidth=2, alpha=0.7)\n",
        "plt.plot(test_indices, y_pred_lin, 's-', label='Linear Regression Predictions',\n",
        "         markersize=6, linewidth=2, alpha=0.7)\n",
        "plt.xlabel('Test Sample Index', fontsize=12)\n",
        "plt.ylabel('Price ($)', fontsize=12)\n",
        "plt.title('Actual vs Linear Regression Predicted House Prices', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Gradient Boosting predictions\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.plot(test_indices, y_test.values, 'o-', label='Actual Prices',\n",
        "         markersize=6, linewidth=2, alpha=0.7)\n",
        "plt.plot(test_indices, y_pred_gb, 's-', label='Gradient Boosting Predictions',\n",
        "         markersize=6, linewidth=2, alpha=0.7)\n",
        "plt.xlabel('Test Sample Index', fontsize=12)\n",
        "plt.ylabel('Price ($)', fontsize=12)\n",
        "plt.title('Actual vs Gradient Boosting Predicted House Prices', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Scatter Plot - Actual vs Predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create subplots for both models\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Linear Regression scatter plot\n",
        "axes[0].scatter(y_test, y_pred_lin, alpha=0.5, s=50, color='steelblue')\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[0].set_xlabel('Actual Price ($)', fontsize=11)\n",
        "axes[0].set_ylabel('Predicted Price ($)', fontsize=11)\n",
        "axes[0].set_title(f'Linear Regression\\nR\u00b2 = {r2_lin:.4f}', fontsize=12, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gradient Boosting scatter plot\n",
        "axes[1].scatter(y_test, y_pred_gb, alpha=0.5, s=50, color='salmon')\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[1].set_xlabel('Actual Price ($)', fontsize=11)\n",
        "axes[1].set_ylabel('Predicted Price ($)', fontsize=11)\n",
        "axes[1].set_title(f'Gradient Boosting\\nR\u00b2 = {r2_gb:.4f}', fontsize=12, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from Gradient Boosting\n",
        "feature_importance_gb = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': gb_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importance - Gradient Boosting:\")\n",
        "print(feature_importance_gb.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from Linear Regression (absolute coefficients)\n",
        "feature_importance_lin = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': np.abs(lin_reg_model.coef_)\n",
        "}).sort_values('Coefficient', ascending=False)\n",
        "\n",
        "print(\"Feature Importance - Linear Regression (Absolute Coefficients):\")\n",
        "print(feature_importance_lin.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot feature importance comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Gradient Boosting feature importance\n",
        "axes[0].barh(feature_importance_gb['Feature'], feature_importance_gb['Importance'], color='steelblue')\n",
        "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
        "axes[0].set_title('Feature Importance - Gradient Boosting', fontsize=12, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3, axis='x')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "# Linear Regression feature importance\n",
        "axes[1].barh(feature_importance_lin['Feature'], feature_importance_lin['Coefficient'], color='salmon')\n",
        "axes[1].set_xlabel('Absolute Coefficient', fontsize=11)\n",
        "axes[1].set_title('Feature Importance - Linear Regression', fontsize=12, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3, axis='x')\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Residual Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals_lin = y_test.values - y_pred_lin\n",
        "residuals_gb = y_test.values - y_pred_gb\n",
        "\n",
        "# Create residual plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Linear Regression residual plot\n",
        "axes[0, 0].scatter(y_pred_lin, residuals_lin, alpha=0.5, color='steelblue')\n",
        "axes[0, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[0, 0].set_xlabel('Predicted Price ($)', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Residuals ($)', fontsize=11)\n",
        "axes[0, 0].set_title('Linear Regression - Residual Plot', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gradient Boosting residual plot\n",
        "axes[0, 1].scatter(y_pred_gb, residuals_gb, alpha=0.5, color='salmon')\n",
        "axes[0, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[0, 1].set_xlabel('Predicted Price ($)', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Residuals ($)', fontsize=11)\n",
        "axes[0, 1].set_title('Gradient Boosting - Residual Plot', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Linear Regression histogram of residuals\n",
        "axes[1, 0].hist(residuals_lin, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "axes[1, 0].set_xlabel('Residuals ($)', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
        "axes[1, 0].set_title('Linear Regression - Residuals Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Gradient Boosting histogram of residuals\n",
        "axes[1, 1].hist(residuals_gb, bins=30, edgecolor='black', alpha=0.7, color='salmon')\n",
        "axes[1, 1].set_xlabel('Residuals ($)', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
        "axes[1, 1].set_title('Gradient Boosting - Residuals Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Model Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare metrics across models\n",
        "metrics_to_plot = ['MAE', 'RMSE', 'R\u00b2 Score']\n",
        "lin_values = [mae_lin, rmse_lin, r2_lin]\n",
        "gb_values = [mae_gb, rmse_gb, r2_gb]\n",
        "\n",
        "x = np.arange(len(metrics_to_plot))\n",
        "width = 0.35\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Absolute values\n",
        "axes[0].bar(x - width/2, [mae_lin, rmse_lin, 0], width, label='Linear Regression', color='steelblue')\n",
        "axes[0].bar(x + width/2, [mae_gb, rmse_gb, 0], width, label='Gradient Boosting', color='salmon')\n",
        "axes[0].set_xlabel('Metrics', fontsize=12)\n",
        "axes[0].set_ylabel('Error Value ($)', fontsize=12)\n",
        "axes[0].set_title('MAE and RMSE Comparison', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xticks(x[:2])\n",
        "axes[0].set_xticklabels(metrics_to_plot[:2])\n",
        "axes[0].legend(fontsize=11)\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# R\u00b2 Score\n",
        "axes[1].bar(['Linear Regression', 'Gradient Boosting'], [r2_lin, r2_gb], \n",
        "            color=['steelblue', 'salmon'], width=0.5)\n",
        "axes[1].set_ylabel('R\u00b2 Score', fontsize=12)\n",
        "axes[1].set_title('R\u00b2 Score Comparison', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylim([0, 1])\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate([r2_lin, r2_gb]):\n",
        "    axes[1].text(i, v + 0.02, f'{v:.4f}', ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Price Prediction Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on specific examples\n",
        "# Example: 3000 sqft, 4 bed, 2.5 bath, built 2010, 2 car garage, no pool, 0.5 lot\n",
        "\n",
        "example_houses = pd.DataFrame({\n",
        "    'SquareFeet': [2000, 3000, 1500],\n",
        "    'Bedrooms': [3, 4, 2],\n",
        "    'Bathrooms': [2, 2.5, 1.5],\n",
        "    'YearBuilt': [2000, 2010, 1990],\n",
        "    'Garage': [2, 2, 1],\n",
        "    'Pool': [0, 1, 0],\n",
        "    'Lot_Size': [0.5, 1.0, 0.25]\n",
        "})\n",
        "\n",
        "# Scale the examples\n",
        "example_scaled = scaler.transform(example_houses)\n",
        "\n",
        "# Predict using both models\n",
        "pred_lin = lin_reg_model.predict(example_scaled)\n",
        "pred_gb = gb_model.predict(example_scaled)\n",
        "\n",
        "# Display results\n",
        "results = pd.DataFrame({\n",
        "    'SquareFeet': example_houses['SquareFeet'],\n",
        "    'Bedrooms': example_houses['Bedrooms'],\n",
        "    'Linear_Reg_Price': pred_lin,\n",
        "    'GB_Predicted_Price': pred_gb,\n",
        "    'Average_Price': (pred_lin + pred_gb) / 2\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"HOUSE PRICE PREDICTIONS FOR NEW EXAMPLES\")\n",
        "print(\"=\"*80)\n",
        "print(results.to_string(index=False))\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 15: Key Findings and Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KEY FINDINGS AND INSIGHTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n1. DATASET OVERVIEW:\")\n",
        "print(f\"   - Total samples: {len(df_clean)}\")\n",
        "print(f\"   - Training samples: {len(X_train)}\")\n",
        "print(f\"   - Testing samples: {len(X_test)}\")\n",
        "print(f\"   - Number of features: {X.shape[1]}\")\n",
        "\n",
        "print(f\"\\n2. PRICE STATISTICS:\")\n",
        "print(f\"   - Average price: ${y.mean():,.2f}\")\n",
        "print(f\"   - Median price: ${y.median():,.2f}\")\n",
        "print(f\"   - Min price: ${y.min():,.2f}\")\n",
        "print(f\"   - Max price: ${y.max():,.2f}\")\n",
        "print(f\"   - Std deviation: ${y.std():,.2f}\")\n",
        "\n",
        "print(f\"\\n3. MODEL PERFORMANCE SUMMARY:\")\n",
        "print(f\"   \\n   LINEAR REGRESSION:\")\n",
        "print(f\"   - MAE: ${mae_lin:,.2f}\")\n",
        "print(f\"   - RMSE: ${rmse_lin:,.2f}\")\n",
        "print(f\"   - R\u00b2 Score: {r2_lin:.4f}\")\n",
        "\n",
        "print(f\"   \\n   GRADIENT BOOSTING:\")\n",
        "print(f\"   - MAE: ${mae_gb:,.2f}\")\n",
        "print(f\"   - RMSE: ${rmse_gb:,.2f}\")\n",
        "print(f\"   - R\u00b2 Score: {r2_gb:.4f}\")\n",
        "\n",
        "improvement_r2 = ((r2_gb - r2_lin) / r2_lin * 100) if r2_lin != 0 else 0\n",
        "print(f\"\\n   Performance improvement (R\u00b2 Score): {improvement_r2:.1f}%\")\n",
        "\n",
        "print(f\"\\n4. TOP 3 MOST IMPORTANT FEATURES:\")\n",
        "print(f\"   \\n   Gradient Boosting:\")\n",
        "for idx, row in feature_importance_gb.head(3).iterrows():\n",
        "    print(f\"   - {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "print(f\"\\n   Linear Regression:\")\n",
        "for idx, row in feature_importance_lin.head(3).iterrows():\n",
        "    print(f\"   - {row['Feature']}: {row['Coefficient']:.2f}\")\n",
        "\n",
        "print(f\"\\n5. RECOMMENDATION:\")\n",
        "print(f\"   - Best Model: {best_model}\")\n",
        "print(f\"   - This model achieves better R\u00b2 score and lower prediction errors.\")\n",
        "\n",
        "print(f\"\\n6. MODEL INTERPRETATION:\")\n",
        "avg_error_lin = mae_lin\n",
        "avg_error_gb = mae_gb\n",
        "print(f\"   - Linear Regression typical error: \u00b1${avg_error_lin:,.2f}\")\n",
        "print(f\"   - Gradient Boosting typical error: \u00b1${avg_error_gb:,.2f}\")\n",
        "print(f\"   - Average house price: ${y.mean():,.2f}\")\n",
        "error_pct_lin = (avg_error_lin / y.mean()) * 100\n",
        "error_pct_gb = (avg_error_gb / y.mean()) * 100\n",
        "print(f\"   - Linear Regression error percentage: {error_pct_lin:.1f}%\")\n",
        "print(f\"   - Gradient Boosting error percentage: {error_pct_gb:.1f}%\")\n",
        "\n",
        "print(f\"\\n7. FEATURE CORRELATIONS WITH PRICE:\")\n",
        "price_corr = df_clean.corr()['Price'].drop('Price').sort_values(ascending=False)\n",
        "for feature, corr in price_corr.head(5).items():\n",
        "    print(f\"   - {feature}: {corr:.4f}\")\n",
        "\n",
        "print(f\"\\n8. CONCLUSION:\")\n",
        "print(f\"   - Both models perform reasonably well for house price prediction.\")\n",
        "print(f\"   - {best_model} captures non-linear relationships better.\")\n",
        "print(f\"   - Square footage and number of bedrooms are key price drivers.\")\n",
        "print(f\"   - The model can be used for property valuation and market analysis.\")\n",
        "print(f\"   - Feature importance analysis helps identify key value factors.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this task, we successfully:\n",
        "1. \u2705 Loaded and inspected the house price dataset\n",
        "2. \u2705 Performed comprehensive exploratory data analysis (EDA)\n",
        "3. \u2705 Cleaned the data and handled missing values\n",
        "4. \u2705 Preprocessed features using StandardScaler\n",
        "5. \u2705 Trained Linear Regression and Gradient Boosting models\n",
        "6. \u2705 Evaluated models using MAE, RMSE, and R\u00b2 metrics\n",
        "7. \u2705 Compared model performance and selected the best one\n",
        "8. \u2705 Visualized actual vs predicted prices\n",
        "9. \u2705 Analyzed feature importance\n",
        "10. \u2705 Performed residual analysis\n",
        "11. \u2705 Made predictions on new examples\n",
        "\n",
        "**Skills Demonstrated:**\n",
        "- Regression modeling with multiple algorithms\n",
        "- Data preprocessing and feature scaling\n",
        "- Exploratory data analysis and visualization\n",
        "- Model evaluation using multiple metrics\n",
        "- Feature importance analysis\n",
        "- Residual analysis and model diagnostics\n",
        "- Real estate data understanding\n",
        "- Price prediction and valuation\n",
        "- Model comparison and selection"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}